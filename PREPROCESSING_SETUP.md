# Diabetes Dataset Preprocessing - Setup Guide

## ğŸš¨ Current Status

All preprocessing code has been created, but your Python environment needs setup.

## ğŸ“‹ What's Been Created

### 1. **Preprocessing Script**
- **File**: `preprocess_diabetes_data.py`
- **Purpose**: Complete end-to-end preprocessing pipeline
- **Features**:
  - Loads diabetic_data.csv
  - Analyzes missing values and data quality
  - Creates binary target (readmitted <30 days)
  - Encodes categorical features with OneHotEncoder
  - Scales numerical features with StandardScaler
  - Saves processed data to data/processed/

### 2. **Jupyter Notebook**
- **File**: `notebooks/data_preprocessing_readmission.ipynb`
- **Purpose**: Interactive step-by-step preprocessing
- **Same features** as the script, but with visualizations and explanations

## ğŸ› ï¸ Setup Instructions

### Option 1: Install Dependencies Globally

```powershell
# First, ensure pip is installed
py -m ensurepip --upgrade

# Install required packages
py -m pip install pandas numpy scikit-learn matplotlib seaborn jupyter
```

### Option 2: Create Virtual Environment (Recommended)

```powershell
# Create virtual environment
py -m venv venv

# Activate it
.\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸš€ Running the Preprocessing

### Method 1: Run Python Script

```powershell
# After installing dependencies
py preprocess_diabetes_data.py
```

**Output files will be saved to:**
- `data/processed/X_features.csv` - Feature matrix (scaled & encoded)
- `data/processed/y_target.csv` - Binary target (1 = readmitted <30 days)
- `data/processed/preprocessor.pkl` - Sklearn pipeline for future use
- `results/figures/readmission_distribution.png`
- `results/figures/binary_target_distribution.png`

### Method 2: Run Jupyter Notebook

```powershell
# Start Jupyter
jupyter notebook

# Open: notebooks/data_preprocessing_readmission.ipynb
# Run all cells sequentially
```

## ğŸ“Š What the Preprocessing Does

### 1. **Data Loading**
- Loads `data/diabetic_data.csv`
- 101,766 rows Ã— 50 columns (expected)

### 2. **Feature Selection**
Selects 15 key features:
- **Demographics**: race, gender, age
- **Hospital metrics**: time_in_hospital
- **Procedures**: num_lab_procedures, num_procedures, num_medications
- **Visits**: number_outpatient, number_inpatient, number_emergency
- **Lab results**: A1Cresult, max_glu_serum
- **Medication**: change, diabetesMed

### 3. **Data Cleaning**
- Replaces '?' with NaN
- Drops rows with missing values
- Expected: ~98,000 clean records

### 4. **Target Creation**
- **Binary classification**: 
  - `y = 1` if readmitted == "<30" (~11% of data)
  - `y = 0` otherwise (~89% of data)
- **Note**: Class imbalance, may need SMOTE or class weights

### 5. **Feature Encoding**
- **Numerical features** (8): StandardScaler normalization
- **Categorical features** (7): OneHotEncoder (drop='first')
- **Final features**: ~30-40 features after one-hot encoding

## ğŸ¯ Expected Results

After preprocessing, you'll have:

```
X_features.csv: ~98,000 rows Ã— 35-40 columns (encoded features)
y_target.csv:   ~98,000 rows Ã— 1 column (0 or 1)
```

**Class distribution:**
- Class 0 (not readmitted <30): ~87,000 samples (89%)
- Class 1 (readmitted <30): ~11,000 samples (11%)

## ğŸ“ˆ Next Steps After Preprocessing

1. **Train/Test Split**
   ```python
   from sklearn.model_selection import train_test_split
   X_train, X_test, y_train, y_test = train_test_split(
       X_final, y, test_size=0.2, random_state=42, stratify=y
   )
   ```

2. **Model Training** (examples)
   ```python
   from sklearn.linear_model import LogisticRegression
   from sklearn.ensemble import RandomForestClassifier
   from xgboost import XGBClassifier
   
   # Handle class imbalance
   model = LogisticRegression(class_weight='balanced')
   model.fit(X_train, y_train)
   ```

3. **Evaluation**
   - ROC-AUC Score
   - Precision-Recall Curve
   - Confusion Matrix
   - Classification Report

## âš ï¸ Troubleshooting

### "No module named pandas"
```powershell
py -m pip install pandas numpy scikit-learn matplotlib seaborn
```

### "No module named pip"
```powershell
py -m ensurepip --upgrade
```

### Python not found
- Install Python 3.8+ from python.org
- Add Python to PATH during installation

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ diabetic_data.csv         # Original dataset (you have this)
â”‚   â””â”€â”€ processed/                # Generated by script
â”‚       â”œâ”€â”€ X_features.csv        # â† Processed features
â”‚       â”œâ”€â”€ y_target.csv          # â† Binary target
â”‚       â””â”€â”€ preprocessor.pkl      # â† Sklearn pipeline
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data_preprocessing_readmission.ipynb  # â† Interactive version
â”œâ”€â”€ results/
â”‚   â””â”€â”€ figures/                  # Visualizations
â”œâ”€â”€ preprocess_diabetes_data.py   # â† Run this script
â””â”€â”€ requirements.txt              # Dependencies
```

## âœ… Quick Start (Copy-Paste)

```powershell
# 1. Install dependencies
py -m pip install pandas numpy scikit-learn matplotlib seaborn

# 2. Run preprocessing
py preprocess_diabetes_data.py

# 3. Check output
ls data/processed/
```

That's it! ğŸ‰
