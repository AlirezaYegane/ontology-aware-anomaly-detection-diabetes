{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Baseline Models for Readmission Prediction\n",
                "\n",
                "This notebook trains and evaluates four baseline models for predicting 30-day hospital readmissions:\n",
                "\n",
                "**Unsupervised Anomaly Detectors:**\n",
                "- Isolation Forest\n",
                "- Autoencoder\n",
                "\n",
                "**Supervised Baselines:**\n",
                "- Decision Tree\n",
                "- Random Forest\n",
                "\n",
                "All models are trained on the same train/test split for fair comparison."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "CWD = Path.cwd().resolve()\n",
                "if CWD.name == \"notebooks\":\n",
                "    PROJECT_ROOT = CWD.parent\n",
                "else:\n",
                "    PROJECT_ROOT = CWD\n",
                "\n",
                "sys.path.insert(0, str(PROJECT_ROOT))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from src.config import GLOBAL_CONFIG\n",
                "from src.preprocessing import load_raw_data, build_feature_matrix, train_test_split_stratified\n",
                "from src.models import (\n",
                "    IsolationForestDetector,\n",
                "    AutoencoderDetector,\n",
                "    DecisionTreeDetector,\n",
                "    RandomForestDetector,\n",
                ")\n",
                "from src.evaluation import compute_classification_metrics, plot_roc_pr_curves\n",
                "\n",
                "# Create results directory\n",
                "results_dir = PROJECT_ROOT / 'results'\n",
                "results_dir.mkdir(exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load raw data\n",
                "data_path = PROJECT_ROOT / 'data' / 'raw' / 'diabetic_data.csv'\n",
                "df = load_raw_data(str(data_path))\n",
                "print(f\"Loaded {len(df):,} records\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build feature matrix\n",
                "X, y, preprocessor = build_feature_matrix(df)\n",
                "print(f\"Feature matrix: {X.shape}\")\n",
                "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
                "print(f\"Positive class (readmitted<30): {y.sum()} ({y.mean()*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/test split using config parameters\n",
                "cfg = GLOBAL_CONFIG\n",
                "X_train, X_test, y_train, y_test = train_test_split_stratified(\n",
                "    X,\n",
                "    y,\n",
                "    test_size=cfg.data.test_size,\n",
                "    random_state=cfg.data.random_seeds[0],\n",
                ")\n",
                "\n",
                "print(f\"Train set: {X_train.shape[0]:,} samples\")\n",
                "print(f\"Test set:  {X_test.shape[0]:,} samples\")\n",
                "print(f\"Train positive rate: {y_train.mean():.4f}\")\n",
                "print(f\"Test positive rate:  {y_test.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Unsupervised Baselines: Isolation Forest & Autoencoder\n",
                "\n",
                "These models treat readmission prediction as an **anomaly detection** problem:\n",
                "- Trained only on **normal samples** (y=0, i.e., not readmitted within 30 days)\n",
                "- Anomaly scores identify patterns that deviate from the normal training distribution\n",
                "- Higher anomaly scores indicate higher risk of readmission"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model 1: Isolation Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter normal samples for training\n",
                "normal_mask_if = (y_train == 0)\n",
                "X_train_normal = X_train[normal_mask_if]\n",
                "\n",
                "print(f\"Training Isolation Forest on {X_train_normal.shape[0]:,} normal samples...\")\n",
                "\n",
                "if_detector = IsolationForestDetector(\n",
                "    n_estimators=cfg.isolation_forest.n_estimators,\n",
                "    contamination=float(y_train.mean()),  # Use actual positive rate\n",
                "    random_state=cfg.isolation_forest.random_state,\n",
                ")\n",
                "if_detector.fit(X_train_normal)\n",
                "\n",
                "print(\"Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute anomaly scores on test set\n",
                "if_scores_test = if_detector.predict_scores(X_test)\n",
                "\n",
                "print(f\"Anomaly scores range: [{if_scores_test.min():.4f}, {if_scores_test.max():.4f}]\")\n",
                "print(f\"Mean score: {if_scores_test.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate Isolation Forest\n",
                "if_metrics = compute_classification_metrics(y_test, if_scores_test, model_name=\"IsolationForest\")\n",
                "\n",
                "print(\"\\nIsolation Forest - Evaluation Results\")\n",
                "print(\"=\"*50)\n",
                "print(f\"ROC-AUC: {if_metrics['roc_auc']:.4f}\")\n",
                "print(f\"PR-AUC:  {if_metrics['pr_auc']:.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot ROC and PR curves\n",
                "plot_roc_pr_curves(\n",
                "    y_test, \n",
                "    if_scores_test, \n",
                "    title=\"Isolation Forest\", \n",
                "    save_path=str(results_dir / 'nb_if_roc_pr.png'),\n",
                "    show=True\n",
                ")\n",
                "print(f\"Plot saved to: {results_dir / 'nb_if_roc_pr.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model 2: Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Training Autoencoder on {X_train_normal.shape[0]:,} normal samples...\")\n",
                "\n",
                "ae_detector = AutoencoderDetector(\n",
                "    input_dim=X_train.shape[1],\n",
                "    hidden_dims=list(cfg.autoencoder.hidden_dims),\n",
                "    epochs=cfg.autoencoder.epochs,\n",
                "    batch_size=cfg.autoencoder.batch_size,\n",
                "    learning_rate=cfg.autoencoder.learning_rate,\n",
                ")\n",
                "\n",
                "ae_detector.fit(X_train_normal)\n",
                "\n",
                "print(\"Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute reconstruction errors on test set\n",
                "ae_scores_test = ae_detector.predict_scores(X_test)\n",
                "\n",
                "print(f\"Reconstruction error range: [{ae_scores_test.min():.6f}, {ae_scores_test.max():.6f}]\")\n",
                "print(f\"Mean reconstruction error: {ae_scores_test.mean():.6f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate Autoencoder\n",
                "ae_metrics = compute_classification_metrics(y_test, ae_scores_test, model_name=\"Autoencoder\")\n",
                "\n",
                "print(\"\\nAutoencoder - Evaluation Results\")\n",
                "print(\"=\"*50)\n",
                "print(f\"ROC-AUC: {ae_metrics['roc_auc']:.4f}\")\n",
                "print(f\"PR-AUC:  {ae_metrics['pr_auc']:.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot ROC and PR curves\n",
                "plot_roc_pr_curves(\n",
                "    y_test, \n",
                "    ae_scores_test, \n",
                "    title=\"Autoencoder\", \n",
                "    save_path=str(results_dir / 'nb_ae_roc_pr.png'),\n",
                "    show=True\n",
                ")\n",
                "print(f\"Plot saved to: {results_dir / 'nb_ae_roc_pr.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Isolation Forest vs Autoencoder\n",
                "\n",
                "**Comparison**:\n",
                "- **Isolation Forest**: Tree-based anomaly detection, fast training, works well with tabular data\n",
                "- **Autoencoder**: Neural network-based, learns complex feature interactions through reconstruction\n",
                "\n",
                "Both models are trained on normal-only data and identify readmissions as anomalies without using labels during training."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Supervised Baselines: Decision Tree & Random Forest\n",
                "\n",
                "These models use **supervised learning** with true readmission labels:\n",
                "- Trained on the full training set with both normal and positive samples\n",
                "- Use class balancing (`class_weight=\"balanced\"`) to handle imbalance\n",
                "- Predict probability scores for the positive class (readmitted <30)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model 3: Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Training Decision Tree on {X_train.shape[0]:,} samples (supervised)...\")\n",
                "\n",
                "dt_detector = DecisionTreeDetector(\n",
                "    max_depth=8,\n",
                "    min_samples_leaf=50,\n",
                "    random_state=42,\n",
                "    class_weight=\"balanced\",\n",
                ")\n",
                "dt_detector.fit(X_train, y_train)\n",
                "\n",
                "print(\"Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute prediction scores\n",
                "dt_scores_test = dt_detector.predict_scores(X_test)\n",
                "\n",
                "print(f\"Prediction scores range: [{dt_scores_test.min():.4f}, {dt_scores_test.max():.4f}]\")\n",
                "print(f\"Mean score: {dt_scores_test.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate Decision Tree\n",
                "dt_metrics = compute_classification_metrics(y_test, dt_scores_test, model_name=\"DecisionTree\")\n",
                "\n",
                "print(\"\\nDecision Tree - Evaluation Results\")\n",
                "print(\"=\"*50)\n",
                "print(f\"ROC-AUC: {dt_metrics['roc_auc']:.4f}\")\n",
                "print(f\"PR-AUC:  {dt_metrics['pr_auc']:.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot ROC and PR curves\n",
                "plot_roc_pr_curves(\n",
                "    y_test, \n",
                "    dt_scores_test, \n",
                "    title=\"Decision Tree (supervised)\", \n",
                "    save_path=str(results_dir / 'nb_dt_roc_pr.png'),\n",
                "    show=True\n",
                ")\n",
                "print(f\"Plot saved to: {results_dir / 'nb_dt_roc_pr.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model 4: Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Training Random Forest on {X_train.shape[0]:,} samples (supervised)...\")\n",
                "\n",
                "rf_detector = RandomForestDetector(\n",
                "    n_estimators=300,\n",
                "    max_depth=None,\n",
                "    min_samples_leaf=50,\n",
                "    random_state=42,\n",
                "    class_weight=\"balanced_subsample\",\n",
                "    n_jobs=-1,\n",
                ")\n",
                "rf_detector.fit(X_train, y_train)\n",
                "\n",
                "print(\"Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute prediction scores\n",
                "rf_scores_test = rf_detector.predict_scores(X_test)\n",
                "\n",
                "print(f\"Prediction scores range: [{rf_scores_test.min():.4f}, {rf_scores_test.max():.4f}]\")\n",
                "print(f\"Mean score: {rf_scores_test.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate Random Forest\n",
                "rf_metrics = compute_classification_metrics(y_test, rf_scores_test, model_name=\"RandomForest\")\n",
                "\n",
                "print(\"\\nRandom Forest - Evaluation Results\")\n",
                "print(\"=\"*50)\n",
                "print(f\"ROC-AUC: {rf_metrics['roc_auc']:.4f}\")\n",
                "print(f\"PR-AUC:  {rf_metrics['pr_auc']:.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot ROC and PR curves\n",
                "plot_roc_pr_curves(\n",
                "    y_test, \n",
                "    rf_scores_test, \n",
                "    title=\"Random Forest (supervised)\", \n",
                "    save_path=str(results_dir / 'nb_rf_roc_pr.png'),\n",
                "    show=True\n",
                ")\n",
                "print(f\"Plot saved to: {results_dir / 'nb_rf_roc_pr.png'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Model Comparison: Supervised vs Unsupervised\n",
                "\n",
                "**Summary Table**:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison DataFrame\n",
                "comparison_df = pd.DataFrame([\n",
                "    {\n",
                "        'Model': 'Isolation Forest',\n",
                "        'Type': 'Unsupervised',\n",
                "        'ROC-AUC': if_metrics['roc_auc'],\n",
                "        'PR-AUC': if_metrics['pr_auc'],\n",
                "    },\n",
                "    {\n",
                "        'Model': 'Autoencoder',\n",
                "        'Type': 'Unsupervised',\n",
                "        'ROC-AUC': ae_metrics['roc_auc'],\n",
                "        'PR-AUC': ae_metrics['pr_auc'],\n",
                "    },\n",
                "    {\n",
                "        'Model': 'Decision Tree',\n",
                "        'Type': 'Supervised',\n",
                "        'ROC-AUC': dt_metrics['roc_auc'],\n",
                "        'PR-AUC': dt_metrics['pr_auc'],\n",
                "    },\n",
                "    {\n",
                "        'Model': 'Random Forest',\n",
                "        'Type': 'Supervised',\n",
                "        'ROC-AUC': rf_metrics['roc_auc'],\n",
                "        'PR-AUC': rf_metrics['pr_auc'],\n",
                "    },\n",
                "])\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"MODEL COMPARISON\")\n",
                "print(\"=\"*70)\n",
                "print(comparison_df.to_string(index=False))\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Key Insights**:\n",
                "\n",
                "1. **Supervised models (DT, RF)** typically achieve **higher metrics** because they use readmission labels during training\n",
                "   - They learn direct patterns associated with readmission\n",
                "   - Require labeled data for training\n",
                "\n",
                "2. **Unsupervised models (IF, AE)** provide a **label-free alternative**:\n",
                "   - Train only on normal patient data\n",
                "   - Identify readmissions as deviations from normal patterns\n",
                "   - Useful when labels are scarce or unreliable\n",
                "\n",
                "3. **Next step**: The ontology layer can enhance unsupervised models by injecting **clinical domain knowledge** without requiring additional labels, bridging the gap with supervised methods."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}