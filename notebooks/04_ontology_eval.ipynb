{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04. Ontology-Aware Evaluation\n",
                "\n",
                "This notebook evaluates the impact of the ontology-inspired rule layer on anomaly detection performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import sys\n",
                "import torch\n",
                "from pathlib import Path\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append('../src')\n",
                "from preprocessing import load_data, get_selected_features, clean_data, create_target, fit_transform_data\n",
                "from models import train_isolation_forest, get_if_anomaly_scores\n",
                "from ontology import apply_ontology_rules, combine_scores\n",
                "from evaluation import evaluate_anomaly_detector, plot_evaluation_curves, print_comparison_table\n",
                "from sklearn.model_selection import train_test_split"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load and Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = '../data/diabetic_data.csv'\n",
                "df = load_data(data_path)\n",
                "features = get_selected_features()\n",
                "df_clean = clean_data(df, features)\n",
                "X, y = create_target(df_clean)\n",
                "X_processed, preprocessor = fit_transform_data(X)\n",
                "\n",
                "# Split data (we need the original df indices to map back to raw features for ontology rules)\n",
                "# We'll split indices instead\n",
                "train_idx, test_idx = train_test_split(df_clean.index, test_size=0.2, stratify=y, random_state=42)\n",
                "\n",
                "X_train = X_processed.loc[train_idx]\n",
                "X_test = X_processed.loc[test_idx]\n",
                "y_train = y.loc[train_idx]\n",
                "y_test = y.loc[test_idx]\n",
                "\n",
                "# Get raw test data for ontology rules\n",
                "df_test_raw = df_clean.loc[test_idx]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Baseline: Isolation Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_normal = X_train[y_train == 0]\n",
                "iso_forest = train_isolation_forest(X_train_normal.values, contamination=0.1)\n",
                "if_scores = get_if_anomaly_scores(iso_forest, X_test.values)\n",
                "\n",
                "# Normalize IF scores to 0-1 range for combination\n",
                "if_scores_norm = (if_scores - if_scores.min()) / (if_scores.max() - if_scores.min())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ontology Layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ontology_penalties = apply_ontology_rules(df_test_raw)\n",
                "print(f\"Ontology penalties computed. Mean: {ontology_penalties.mean():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Combine and Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_scores = combine_scores(if_scores_norm, ontology_penalties.values, alpha=0.7, beta=0.3)\n",
                "\n",
                "metrics_if = evaluate_anomaly_detector(y_test, if_scores_norm, model_name=\"Isolation Forest\")\n",
                "metrics_combined = evaluate_anomaly_detector(y_test, final_scores, model_name=\"Combined (IF + Ontology)\")\n",
                "\n",
                "print_comparison_table([metrics_if, metrics_combined])\n",
                "\n",
                "plot_evaluation_curves(y_test, {\n",
                "    \"Isolation Forest\": if_scores_norm,\n",
                "    \"Combined\": final_scores\n",
                "})"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}