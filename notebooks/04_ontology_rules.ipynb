{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04 - Ontology Rules Validation\n",
                "\n",
                "Validate ML-detected anomalies using domain-specific ontological rules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from src.data_loader import load_raw_data\n",
                "from src.ontology_rules import (\n",
                "    OntologyRuleEngine,\n",
                "    create_diabetes_rules,\n",
                "    validate_with_ontology\n",
                ")\n",
                "\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Data with Anomaly Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load anomaly detection results\n",
                "from pathlib import Path\n",
                "\n",
                "results_path = Path('..') / 'results' / 'reports' / 'anomaly_detection_results.csv'\n",
                "\n",
                "if results_path.exists():\n",
                "    df = pd.read_csv(results_path)\n",
                "    print(f\"Loaded results with anomaly predictions: {df.shape}\")\n",
                "else:\n",
                "    print(\"Anomaly detection results not found. Using raw data...\")\n",
                "    df = load_raw_data()\n",
                "    # Create dummy anomaly column for demonstration\n",
                "    df['high_confidence_anomaly'] = False\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define Ontology Rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create rule engine with diabetes-specific rules\n",
                "rule_engine = create_diabetes_rules()\n",
                "\n",
                "print(\"Ontology Rules:\")\n",
                "for idx, rule in enumerate(rule_engine.rules, 1):\n",
                "    print(f\"{idx}. {rule['name']}: {rule['description']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Apply Ontology Rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate with ontology\n",
                "anomaly_col = 'high_confidence_anomaly' if 'high_confidence_anomaly' in df.columns else None\n",
                "\n",
                "df_validated, analysis = validate_with_ontology(df, anomaly_col=anomaly_col)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Rule Violation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display rule violation summary\n",
                "print(\"\\nRule Violation Summary:\")\n",
                "print(analysis['rule_violation_summary'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize rule violations\n",
                "violation_summary = analysis['rule_violation_summary']\n",
                "\n",
                "if len(violation_summary) > 0:\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    violation_summary['violations'].plot(kind='barh', color='coral')\n",
                "    plt.xlabel('Number of Violations')\n",
                "    plt.title('Ontology Rule Violations by Rule Type')\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compare ML Anomalies vs Rule Violations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze overlap\n",
                "if anomaly_col and 'has_rule_violation' in df_validated.columns:\n",
                "    print(\"\\n=== ML vs Ontology Comparison ===\")\n",
                "    print(f\"Total ML anomalies: {analysis.get('total_ml_anomalies', 0)}\")\n",
                "    print(f\"Total rule violations: {analysis.get('total_rule_violations', 0)}\")\n",
                "    print(f\"\\nConfirmed anomalies (both ML & rules): {analysis.get('confirmed_anomalies', 0)}\")\n",
                "    print(f\"ML only (no rule violation): {analysis.get('ml_only_anomalies', 0)}\")\n",
                "    print(f\"Rules only (not ML anomaly): {analysis.get('rule_only_violations', 0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Venn diagram visualization\n",
                "if anomaly_col and 'has_rule_violation' in df_validated.columns:\n",
                "    from matplotlib_venn import venn2\n",
                "    \n",
                "    plt.figure(figsize=(8, 6))\n",
                "    \n",
                "    venn2(\n",
                "        subsets=(\n",
                "            analysis.get('ml_only_anomalies', 0),\n",
                "            analysis.get('rule_only_violations', 0),\n",
                "            analysis.get('confirmed_anomalies', 0)\n",
                "        ),\n",
                "        set_labels=('ML Anomalies', 'Rule Violations'),\n",
                "        set_colors=('skyblue', 'coral'),\n",
                "        alpha=0.7\n",
                "    )\n",
                "    \n",
                "    plt.title('Overlap Between ML Anomalies and Ontology Rule Violations')\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Examine Confirmed Anomalies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get records that are both ML anomalies AND violate rules\n",
                "if anomaly_col and 'has_rule_violation' in df_validated.columns:\n",
                "    confirmed = df_validated[\n",
                "        (df_validated[anomaly_col] == True) & \n",
                "        (df_validated['has_rule_violation'] == True)\n",
                "    ]\n",
                "    \n",
                "    print(f\"\\nConfirmed Anomalies: {len(confirmed)}\")\n",
                "    print(\"\\nSample confirmed anomalies:\")\n",
                "    \n",
                "    # Show which rules they violate\n",
                "    violation_cols = [col for col in confirmed.columns if col.startswith('violates_')]\n",
                "    display_cols = violation_cols[:5] if len(violation_cols) > 5 else violation_cols\n",
                "    \n",
                "    confirmed[display_cols].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze which rules are most commonly violated by ML-detected anomalies\n",
                "if anomaly_col and 'has_rule_violation' in df_validated.columns:\n",
                "    ml_anomalies = df_validated[df_validated[anomaly_col] == True]\n",
                "    \n",
                "    print(\"\\nRule violations among ML-detected anomalies:\")\n",
                "    violation_counts = {}\n",
                "    \n",
                "    for col in violation_cols:\n",
                "        rule_name = col.replace('violates_', '')\n",
                "        count = ml_anomalies[col].sum()\n",
                "        pct = (count / len(ml_anomalies) * 100) if len(ml_anomalies) > 0 else 0\n",
                "        violation_counts[rule_name] = count\n",
                "        print(f\"  {rule_name}: {count} ({pct:.1f}%)\")\n",
                "    \n",
                "    # Visualize\n",
                "    if violation_counts:\n",
                "        plt.figure(figsize=(10, 5))\n",
                "        plt.bar(violation_counts.keys(), violation_counts.values(), color='steelblue', alpha=0.7)\n",
                "        plt.xlabel('Rule Type')\n",
                "        plt.ylabel('Violation Count')\n",
                "        plt.title('Rule Violations Among ML-Detected Anomalies')\n",
                "        plt.xticks(rotation=45, ha='right')\n",
                "        plt.tight_layout()\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Final Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save validated results\n",
                "output_path = Path('..') / 'results' / 'reports' / 'ontology_validated_results.csv'\n",
                "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "df_validated.to_csv(output_path, index=False)\n",
                "\n",
                "print(f\"\\nValidated results saved to: {output_path}\")\n",
                "\n",
                "# Save analysis summary\n",
                "import json\n",
                "\n",
                "summary_path = Path('..') / 'results' / 'reports' / 'validation_summary.json'\n",
                "\n",
                "# Convert DataFrame to dict for JSON serialization\n",
                "analysis_json = {k: v for k, v in analysis.items() if k != 'rule_violation_summary'}\n",
                "analysis_json['rule_violation_summary'] = analysis['rule_violation_summary'].to_dict()\n",
                "\n",
                "with open(summary_path, 'w') as f:\n",
                "    json.dump(analysis_json, f, indent=2)\n",
                "\n",
                "print(f\"Validation summary saved to: {summary_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusions\n",
                "\n",
                "**Key Findings:**\n",
                "\n",
                "1. **ML Anomaly Detection**: Identified anomalies using ensemble of methods\n",
                "2. **Ontology Validation**: Applied domain-specific rules to validate findings\n",
                "3. **Confirmed Anomalies**: Records flagged by both ML and ontology rules represent high-confidence issues\n",
                "4. **ML-Only Anomalies**: May represent novel patterns not captured by current rules\n",
                "5. **Rule-Only Violations**: Data quality issues that don't show unusual statistical patterns\n",
                "\n",
                "**Next Steps:**\n",
                "- Investigate confirmed anomalies for clinical significance\n",
                "- Refine ontology rules based on domain expert feedback\n",
                "- Update ML models with validated anomaly labels\n",
                "- Consider semi-supervised approaches combining both methods"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}