{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exploratory Data Analysis\n",
                "\n",
                "This notebook provides an exploratory analysis of the **Diabetes 130-US Hospitals (1999-2008)** dataset.\n",
                "\n",
                "**Problem Setting**: The goal of this project is to predict **30-day hospital readmissions** using an anomaly detection approach. Patients readmitted within 30 days (`readmitted == \"<30\"`) are treated as the positive class (anomalies), while others are considered normal cases."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "CWD = Path.cwd().resolve()\n",
                "if CWD.name == \"notebooks\":\n",
                "    PROJECT_ROOT = CWD.parent\n",
                "else:\n",
                "    PROJECT_ROOT = CWD\n",
                "\n",
                "sys.path.insert(0, str(PROJECT_ROOT))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from src.preprocessing import load_raw_data\n",
                "\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.dpi'] = 100"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = PROJECT_ROOT / 'data' / 'raw' / 'diabetic_data.csv'\n",
                "\n",
                "if not data_path.exists():\n",
                "    print(f\"Data file not found at {data_path}\")\n",
                "    print(\"Please ensure the dataset is in the data/raw/ directory.\")\n",
                "else:\n",
                "    df = load_raw_data(str(data_path))\n",
                "    print(f\"Dataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Dataset shape:\", df.shape)\n",
                "print(\"\\nColumn dtypes:\")\n",
                "print(df.dtypes.value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Target Variable: Readmission Status\n",
                "\n",
                "The `readmitted` column indicates whether a patient was readmitted:\n",
                "- `\"NO\"`: Not readmitted\n",
                "- `\">30\"`: Readmitted after 30 days\n",
                "- `\"<30\"`: **Readmitted within 30 days** (our positive class for anomaly detection)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Readmission distribution:\")\n",
                "print(df['readmitted'].value_counts())\n",
                "print(f\"\\nPercentage readmitted <30 days: {(df['readmitted'] == '<30').mean() * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(data=df, x='readmitted', order=['NO', '>30', '<30'], palette='viridis')\n",
                "plt.title('Distribution of Readmission Status', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Readmission Status')\n",
                "plt.ylabel('Count')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Missing Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "missing_data = df.isnull().sum()\n",
                "missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
                "\n",
                "if len(missing_data) > 0:\n",
                "    print(\"Columns with missing values:\")\n",
                "    print(missing_data)\n",
                "else:\n",
                "    print(\"No missing values detected (NaN)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for '?' placeholder values (common in this dataset)\n",
                "question_mark_cols = []\n",
                "for col in df.columns:\n",
                "    if df[col].dtype == 'object':\n",
                "        if '?' in df[col].values:\n",
                "            count = (df[col] == '?').sum()\n",
                "            question_mark_cols.append((col, count))\n",
                "\n",
                "if question_mark_cols:\n",
                "    print(\"Columns with '?' placeholder:\")\n",
                "    for col, count in sorted(question_mark_cols, key=lambda x: x[1], reverse=True):\n",
                "        print(f\"  {col}: {count:,} ({count/len(df)*100:.2f}%)\")\n",
                "else:\n",
                "    print(\"No '?' placeholders found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Numerical Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
                "print(f\"Numerical features ({len(numerical_cols)}): {numerical_cols}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df[numerical_cols].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Key Feature Distributions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select important features for visualization\n",
                "key_features = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', \n",
                "                'num_medications', 'number_outpatient', 'number_emergency', \n",
                "                'number_inpatient', 'number_diagnoses']\n",
                "\n",
                "available_features = [f for f in key_features if f in df.columns]\n",
                "\n",
                "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, feature in enumerate(available_features):\n",
                "    if i < len(axes):\n",
                "        df[feature].hist(bins=30, ax=axes[i], edgecolor='black', alpha=0.7)\n",
                "        axes[i].set_title(feature, fontsize=10)\n",
                "        axes[i].set_xlabel('')\n",
                "        axes[i].set_ylabel('Frequency')\n",
                "\n",
                "# Hide unused subplots\n",
                "for j in range(i+1, len(axes)):\n",
                "    axes[j].axis('off')\n",
                "\n",
                "plt.suptitle('Distribution of Key Numerical Features', fontsize=14, fontweight='bold', y=1.00)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Categorical Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
                "print(f\"Categorical features ({len(categorical_cols)}):\")\n",
                "print(categorical_cols)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show cardinality for each categorical feature\n",
                "cat_cardinality = {col: df[col].nunique() for col in categorical_cols}\n",
                "cat_cardinality_sorted = sorted(cat_cardinality.items(), key=lambda x: x[1], reverse=True)\n",
                "\n",
                "print(\"Categorical feature cardinality:\")\n",
                "for col, count in cat_cardinality_sorted[:15]:  # Show top 15\n",
                "    print(f\"  {col}: {count} unique values\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Correlation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if len(numerical_cols) > 1:\n",
                "    plt.figure(figsize=(12, 10))\n",
                "    corr_matrix = df[numerical_cols].corr()\n",
                "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', \n",
                "                linewidths=0.5, cbar_kws={'label': 'Correlation'})\n",
                "    plt.title('Correlation Matrix of Numerical Features', fontsize=14, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "**Key Findings**:\n",
                "- The dataset exhibits **class imbalance**: patients readmitted within 30 days represent a minority class\n",
                "- Several columns use `'?'` as a placeholder for missing values\n",
                "- Important clinical features include hospital utilization patterns (emergency visits, inpatient admissions) and medication/procedure counts\n",
                "- High cardinality in some categorical features (e.g., diagnosis codes) may require careful encoding\n",
                "\n",
                "**Next Steps**: The preprocessing pipeline will handle missing values, encode categorical features, and scale numerical features before feeding data to anomaly detection models."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}